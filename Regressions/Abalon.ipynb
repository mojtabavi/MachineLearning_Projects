{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_pipeline\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, KFold, LeaveOneGroupOut, GridSearchCV, RandomizedSearchCV \n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bias_variance_decomp\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer, PowerTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneGroupOut, GridSearchCV, RandomizedSearchCV \n",
    "\n",
    "from mlxtend.evaluate import bias_variance_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_abalone = pd.read_csv('../Data/abalone/abalone.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abalone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abalone.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abalone.columns = ['sex', 'length', 'diameter', 'height', 'whole_weight', 'shucked_weight', 'viscera_weight', 'shell_weight', 'rings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_abalone.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_abalone.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sex']] = df[['sex']].astype('category')\n",
    "df[['rings']] = df[['rings']].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['sex'], dtype=np.float64)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'sex_F':'sex_f', 'sex_I':'sex_i', 'sex_M':'sex_m'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data distribution\n",
    "plt.title('Price Distribution Plot')\n",
    "sns.distplot(df['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 11))\n",
    "sns.heatmap(df.corr(), annot=True, mask=np.triu(df.corr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_abalone['shell_weight'], data_abalone['rings'], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set = np.array(df.drop(['rings'], axis=1))\n",
    "y_set = np.array(df['rings'])\n",
    "\n",
    "x_set_mini = np.array(df['shell_weight'])\n",
    "y_set_mini = np.array(df['rings'])\n",
    "\n",
    "x_set.shape, y_set.shape, x_set_mini.shape, y_set_mini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = data_abalone.copy()\n",
    "dfe[['sex']] = dfe[['sex']].astype('category')\n",
    "dfe[['rings']] = dfe[['rings']].astype('float64')\n",
    "dfe = pd.get_dummies(dfe, columns=['sex'], dtype=np.float64)\n",
    "dfe.rename(columns={'sex_F':'sex_f', 'sex_I':'sex_i', 'sex_M':'sex_m'}, inplace=True)\n",
    "x_set1 = np.array(df.drop(['rings'], axis=1))\n",
    "y_set1 = np.array(df['rings'])\n",
    "x_set1.shape, y_set1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = MinMaxScaler()\n",
    "y_set1 = standard.fit_transform(y_set1[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_set1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "score_hist = []\n",
    "lr = 0.03\n",
    "\n",
    "n_epochs = 3000\n",
    "d=2\n",
    "\n",
    "polynomial = PolynomialFeatures(degree=d)\n",
    "model = SGDRegressor(eta0=lr)\n",
    "\n",
    "x_set_poly = polynomial.fit_transform(x_set)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.partial_fit(x_set_poly, y_set1.ravel())\n",
    "\n",
    "    y_hat = model.predict(x_set_poly)\n",
    "    loss_train = mean_absolute_error(y_set1, y_hat)\n",
    "    loss_hist.append(loss_train)\n",
    "\n",
    "    score = r2_score(y_set1, y_hat)\n",
    "    score_hist.append(score)\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch={epoch}, \\t Loss={loss_train:.4},\\t score={score:.4}')\n",
    "        \n",
    "print(f'Model weights: {model.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 202\n",
    "x_set_poly = polynomial.transform(x_set[[q], :])\n",
    "y = model.predict(x_set_poly)\n",
    "(y*29).round() , (y_set1[q]*29).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1_hist = []\n",
    "score1_hist = []\n",
    "\n",
    "loss2_hist = []\n",
    "score2_hist = []\n",
    "\n",
    "loss3_hist = []\n",
    "score3_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 3000\n",
    "random_seed = 14\n",
    "\n",
    "model = SGDRegressor(eta0=lr, random_state=random_seed)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.partial_fit(x_set_mini[:, None], y_set_mini.ravel())\n",
    "\n",
    "    y_hat = model.predict(x_set_mini[:, None])\n",
    "    loss_train = mean_absolute_error(y_set_mini, y_hat)\n",
    "    loss2_hist.append(loss_train)\n",
    "\n",
    "    score = r2_score(y_set_mini, y_hat)\n",
    "    score2_hist.append(score)\n",
    "\n",
    "    if (epoch+1) % 100 == 0 or epoch<10:\n",
    "        print(f'Epoch={epoch}, \\t Loss={loss_train:.4},\\t score={score:.4}')\n",
    "        \n",
    "print(f'Model weights: {model.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax[0].plot(loss1_hist, label='lr=0.1')\n",
    "ax[0].plot(loss2_hist, label='lr=0.01')\n",
    "ax[0].plot(loss3_hist, label='lr=0.001')\n",
    "ax[0].legend()\n",
    "ax[0].grid()\n",
    "ax[0].set_title('Learning Curve for Loss')\n",
    "\n",
    "ax[1].plot(score1_hist, label='lr=0.1')\n",
    "ax[1].plot(score2_hist, label='lr=0.01')\n",
    "ax[1].plot(score3_hist, label='lr=0.001')\n",
    "ax[1].legend()\n",
    "ax[1].grid()\n",
    "ax[1].set_title('Learning Curve for R2_score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss1_hist, label='lr=0.1')\n",
    "plt.plot(loss2_hist, label='lr=0.01')\n",
    "plt.plot(loss3_hist, label='lr=0.001')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Learning Curve for Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(score1_hist, label='lr=0.1')\n",
    "plt.plot(score2_hist, label='lr=0.01')\n",
    "plt.plot(score3_hist, label='lr=0.001')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Learning Curve for R2_score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(x_set_mini.min(), x_set_mini.max(), 100)[:, None]\n",
    "y_hat = model.predict(x)\n",
    "\n",
    "plt.scatter(x_set_mini, y_set_mini, alpha=0.2)\n",
    "plt.plot(x, y_hat, 'r', linewidth=3)\n",
    "plt.title('linear regression on data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = [[], [], []]\n",
    "score_hist = [[], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 3000\n",
    "ds=[1, 2, 3]\n",
    "random_seed = 14\n",
    "polynomials = []\n",
    "models = []\n",
    "\n",
    "for d in ds: \n",
    "    polynomial = PolynomialFeatures(degree=d)\n",
    "    model = SGDRegressor(eta0=lr, random_state=random_seed)\n",
    "\n",
    "    x_set_poly = polynomial.fit_transform(x_set_mini[:, None])\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.partial_fit(x_set_poly, y_set_mini.ravel())\n",
    "\n",
    "        y_hat = model.predict(x_set_poly)\n",
    "        loss_train = mean_absolute_error(y_set_mini, y_hat)\n",
    "        loss_hist[d-1].append(loss_train)\n",
    "\n",
    "        score = r2_score(y_set_mini, y_hat)\n",
    "        score_hist[d-1].append(score)\n",
    "\n",
    "        if (epoch+1) % 100 == 0 or epoch<10:\n",
    "            print(f'd={d}, Epoch={epoch}, \\t Loss={loss_train:.4},\\t score={score:.4}')\n",
    "    \n",
    "    polynomials.append(polynomial)\n",
    "    models.append(model)\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= ['r', 'orange', 'g']\n",
    "fig, ax =plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "for d in ds:\n",
    "    ax[0].plot(loss_hist[d-1], color=c[d-1], label=f'd={d}')\n",
    "    ax[1].plot(score_hist[d-1], color=c[d-1], label=f'd={d}')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].grid()\n",
    "ax[0].set_title('Learning Curve for Loss')\n",
    "ax[1].legend()\n",
    "ax[1].grid()\n",
    "ax[1].set_title('Learning Curve for R2_score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_set_mini, y_set_mini, alpha=0.2)\n",
    "c= ['r', 'orange', 'g']\n",
    "for d in ds:\n",
    "    x = np.linspace(x_set_mini.min(), x_set_mini.max(), 100)[:, None]\n",
    "    xp = polynomials[d-1].transform(x)\n",
    "    y_hat = models[d-1].predict(xp)\n",
    "    plt.plot(x, y_hat, color=c[d-1],linewidth=3, label=f'd={d}')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('polynomial regression on data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = [[], [], [], []]\n",
    "score_hist = [[], [], [], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda x: 1/(x + 0.9)**3\n",
    "log = lambda x: np.log(x+0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 1000\n",
    "fs={'power_transform':'yeo_johnson', 'log(x+0.3)':log, 'exp(x)':np.exp, '1/(x+0.9)^3':func}\n",
    "random_seed = 14\n",
    "basis_function = []\n",
    "models = []\n",
    "\n",
    "for i, (k, f) in enumerate(fs.items()): \n",
    "    if i==0:\n",
    "        basis = PowerTransformer()\n",
    "    else:\n",
    "        basis = FunctionTransformer(f)\n",
    "\n",
    "    model = SGDRegressor(eta0=lr, random_state=random_seed)\n",
    "\n",
    "    x_set_poly = basis.fit_transform(x_set_mini[:, None])\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.partial_fit(x_set_poly, y_set_mini.ravel())\n",
    "\n",
    "        y_hat = model.predict(x_set_poly)\n",
    "        loss_train = mean_absolute_error(y_set_mini, y_hat)\n",
    "        loss_hist[i].append(loss_train)\n",
    "\n",
    "        score = r2_score(y_set_mini, y_hat)\n",
    "        score_hist[i].append(score)\n",
    "\n",
    "        if (epoch+1) % 100 == 0 or epoch<10:\n",
    "            print(f'f={k}, Epoch={epoch}, \\t Loss={loss_train:.4},\\t score={score:.4}')\n",
    "    \n",
    "    basis_function.append(basis)\n",
    "    models.append(model)\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= ['r', 'orange', 'g', 'c']\n",
    "fig, ax =plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "for i, (k, v) in enumerate(fs.items()):\n",
    "    ax[0].plot(loss_hist[i], color=c[i], label=f'function={k}')\n",
    "    ax[1].plot(score_hist[i], color=c[i], label=f'function={k}')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].grid()\n",
    "ax[0].set_title('Learning Curve for Loss')\n",
    "ax[1].legend()\n",
    "ax[1].grid()\n",
    "ax[1].set_title('Learning Curve for R2_score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= ['r', 'orange', 'g', 'c']\n",
    "plt.scatter(x_set_mini, y_set_mini, alpha=0.2)\n",
    "\n",
    "for i, (k, f) in enumerate(fs.items()):\n",
    "    x = np.linspace(x_set_mini.min(), x_set_mini.max(), 100)[:, None]\n",
    "    xp = basis_function[i].transform(x)\n",
    "    y_hat = models[i].predict(xp)\n",
    "    plt.plot(x, y_hat, color=c[i],linewidth=3, label=f'function={k}')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Other basis function regression on data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set_mini = np.array(df['shell_weight'])\n",
    "y_set_mini = np.array(df['rings'])\n",
    "\n",
    "x_mini, _, y_mini, _ = train_test_split(x_set_mini, y_set_mini, test_size=0.8801, random_state=14, shuffle=True)\n",
    "\n",
    "x_mini.shape, y_mini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_mini, y_mini, test_size=0.8, random_state=14, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train, alpha=1)\n",
    "plt.scatter(x_valid, y_valid, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_hist = [[]]\n",
    "score_train_hist = [[]]\n",
    "\n",
    "loss_valid_hist = [[]]\n",
    "score_valid_hist = [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda x: 1/(x + 0.9)**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 1000\n",
    "fs={'1/(x+0.9)^3':func}\n",
    "random_seed = 14\n",
    "basis_function = []\n",
    "models = []\n",
    "\n",
    "for i, (k, f) in enumerate(fs.items()): \n",
    "        \n",
    "    basis = FunctionTransformer(f)\n",
    "\n",
    "    model = SGDRegressor(eta0=lr, random_state=random_seed)\n",
    "\n",
    "    x_train_poly = basis.fit_transform(x_train[:, None])\n",
    "    x_valid_poly = basis.transform(x_valid[:, None])\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.partial_fit(x_train_poly, y_train.ravel())\n",
    "\n",
    "        #train\n",
    "        y_hat = model.predict(x_train_poly)\n",
    "        loss_train = mean_absolute_error(y_train, y_hat)\n",
    "        loss_train_hist[i].append(loss_train)\n",
    "\n",
    "        score_train = r2_score(y_train, y_hat)\n",
    "        score_train_hist[i].append(score_train)\n",
    "\n",
    "        #valid\n",
    "        y_hat = model.predict(x_valid_poly)\n",
    "        loss_valid = mean_absolute_error(y_valid, y_hat)\n",
    "        loss_valid_hist[i].append(loss_valid)\n",
    "\n",
    "        score_valid = r2_score(y_valid, y_hat)\n",
    "        score_valid_hist[i].append(score_valid)\n",
    "\n",
    "        \n",
    "\n",
    "        if (epoch+1) % 100 == 0 or epoch<10:\n",
    "            print(f'f={k}, Epoch={epoch}, \\t Loss_train={loss_train:.4},\\t score_train={score_train:.4}, \\t Loss_valid={loss_valid:.4},\\t score_valid={score_valid:.4}')\n",
    "    \n",
    "    basis_function.append(basis)\n",
    "    models.append(model)\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax =plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "for i, (k, v) in enumerate(fs.items()):\n",
    "    ax[0].plot(loss_train_hist[i], label=f'train={k}')\n",
    "    ax[1].plot(score_train_hist[i], label=f'train={k}')\n",
    "\n",
    "    ax[0].plot(loss_valid_hist[i], label=f'valid={k}')\n",
    "    ax[1].plot(score_valid_hist[i], label=f'valid={k}')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].grid()\n",
    "ax[0].set_title('Learning Curve for Loss')\n",
    "ax[1].legend()\n",
    "ax[1].grid()\n",
    "ax[1].set_title('Learning Curve for R2_score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(x_mini, y_mini, alpha=0.2)\n",
    "\n",
    "for i, (k, f) in enumerate(fs.items()):\n",
    "    x = np.linspace(x_mini.min(), x_mini.max(), 100)[:, None]\n",
    "    xp = basis_function[i].transform(x)\n",
    "    y_hat = models[i].predict(xp)\n",
    "    plt.plot(x, y_hat,linewidth=3, label=f'function={k}')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Other basis function regression on data');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
